# Requires the Docker Compose V2.
# See https://docs.docker.com/compose/compose-file/compose-file-v3
# and https://github.com/compose-spec/compose-spec/blob/master/spec.md
# for details concerning the `docker-compose.yaml` file syntax.

# Variables are in ${VARIABLE:-DEFAULT_VALUE} format
# to ensure that default values are given to the Dockerfile.
# Using a `.env` file to set variables is strongly recommended.

# Run `make env` to create a basic `.env` file with the UID and GID variables.
# Compute Capability must be specified via the `CCA` variable.

# Using a `docker-compose.yaml` file has many advantages
# over creating custom shell scripts for each project.
# The settings are much easier to see and maintain than scattered shell scripts.
# Also, Compose is a native Docker component, simplifying project maintenance.

# Set the host environment variable `BUILDKIT_PROGRESS=plain` to see the full build log.
# https://github.com/docker/cli/blob/master/docs/reference/commandline/cli.md#environment-variables

# See https://pytorch.org/docs/stable/cpp_extension.html for an
# explanation of how to specify the `TORCH_CUDA_ARCH_LIST` variable.
# The variable `CCA` is used to specify `TORCH_CUDA_ARCH_LIST`.


services:
  train:  # Service name. Change the name as necessary for each project.
    hostname: train  # Set to be the same as the service name. Makes terminals easier to tell apart.
    # Use different image names for different users and projects.
    # Otherwise, images will be repeatedly removed and recreated.
    # The removed images will remain cached, however.
    image: cresset:${IMAGE_NAME:-train}
    # `ipc: host` removes the shared memory cap but is a known security vulnerability.
#    ipc: host  # Equivalent to `--ipc=host` in `docker run`. Disable this for WSL.
#    shm_size: 1GB  # Explicit shared memory limit. No security issues this way.
    tty: true  # Equivalent to `-t` flag in `docker run`.
    init: true  # Equivalent to `--init` flag in `docker run`.
    stdin_open: true  # equivalent to `-i` flag in `docker run`.
    # Setting `HOST_PATH:CONTAINER_PATH` allows the container to access `HOST_PATH` as `CONTAINER_PATH`.
    # See https://docs.docker.com/storage/volumes for details.
    # Current working directory `.` is connected to `PROJECT_ROOT`.
    # Always use the ${HOME} variable to specify the host home directory.
    # The `~` expands to the directory inside the image, not the user home directory.
    # See https://github.com/docker/compose/issues/6506 for details.
    volumes:  # Equivalent to `-v` flag in `docker run`.
      - .:${PROJECT_ROOT:-/opt/project}  # Use this if the docker-compose.yaml file is at the project root.
#      - ..:${PROJECT_ROOT:-/opt/project}  # Use this if the docker-compose.yaml file is in a subdirectory.
    build:  # Options for building. Used when `--build` is called in `docker compose`.
      target: train  # Specify build target.
      context: .
      dockerfile: Dockerfile
      args:  # Equivalent to `--build-arg`.
        BUILD_MODE: ${BUILD_MODE:-exclude}
        TORCH_CUDA_ARCH_LIST: ${CCA}  # This will fail if BUILD_MODE=include but CCA is not set explicitly.
        PYTORCH_VERSION_TAG: ${PYTORCH_VERSION_TAG:-v1.11.0}
        TORCHVISION_VERSION_TAG: ${TORCHVISION_VERSION_TAG:-v0.12.0}
        TORCHTEXT_VERSION_TAG: ${TORCHTEXT_VERSION_TAG:-v0.12.0}
        PROJECT_ROOT: ${PROJECT_ROOT:-/opt/project}
        GID: ${GID:-1000}  # `id -g`
        UID: ${UID:-1000}  # `id -u`
        GRP: ${GRP:-user}  # `id -gn`
        USR: ${USR:-user}  # `id -un`
        TZ: ${TZ:-Asia/Seoul}  # Timezone settings used during the build.
#        DEB_OLD: ${DEB_OLD:-http://archive.ubuntu.com}
#        DEB_NEW: ${DEB_NEW:-http://mirror.kakao.com}
#        INDEX_URL: ${INDEX_URL:-http://mirror.kakao.com/pypi/simple}
#        TRUSTED_HOST: ${TRUSTED_HOST:-mirror.kakao.com}
    working_dir: ${PROJECT_ROOT:-/opt/project}
#    ports:  # Uncomment if ports are necessary.
#      - ${PORT:-8080}:22
    user: ${UID:-1000}:${GID:-1000}
    environment:  # Environment variables for the container, not the build. Equivalent to `--env`
      TZ: ${TZ:-Asia/Seoul}  # Timezone settings used during runtime.
      CUDA_DEVICE_ORDER: PCI_BUS_ID
    deploy:  # API dependent on compose version.
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
#              device_ids: [ "0" ]  # Use only GPU 0.


  full:  # Default service name. Change the name as necessary for each project.
    hostname: full
    image: cresset:${IMAGE_NAME:-full}
#    ipc: host
#    shm_size: 1GB
    tty: true
    init: true
    stdin_open: true
#    tmpfs:  # Create directory in RAM for fast data IO.
#      - /opt/data
    volumes:  # Place user-specific directories in `docker-compose.override.yaml`.
      - .:${PROJECT_ROOT:-/opt/project}
#      - ${HOME}/.vscode-server:/home/${USR}/.vscode-server  # VSCode extensions can be preserved between containers this way.
    build:
      # Set `TARGET_STAGE` to `train-builds` to get just the wheels in `/tmp/dist`.
      target: ${TARGET_STAGE:-train}
      context: .
      dockerfile: Dockerfile
      args:  # Equivalent to `--build-arg`.
        BUILD_MODE: ${BUILD_MODE:-exclude}
        BUILD_CAFFE2: 0  # Caffe2 disabled for faster build.
        BUILD_CAFFE2_OPS: 0
        BUILD_TEST: 0
        USE_NNPACK: 0
        USE_QNNPACK: 0
        LINUX_DISTRO: ${LINUX_DISTRO:-ubuntu}
        DISTRO_VERSION: ${DISTRO_VERSION:-18.04}
        CUDA_VERSION: ${CUDA_VERSION:-10.2}
        CUDNN_VERSION: ${CUDNN_VERSION:-8}
        PYTHON_VERSION: ${PYTHON_VERSION:-3.9}
        MKL_MODE: ${MKL_MODE:-include}  # MKL_MODE can be `include` or `exclude`.
        TORCH_CUDA_ARCH_LIST: ${CCA}  # This will fail if BUILD_MODE=include but CCA is not set explicitly.
        PYTORCH_VERSION_TAG: ${PYTORCH_VERSION_TAG:-v1.11.0}
        TORCHVISION_VERSION_TAG: ${TORCHVISION_VERSION_TAG:-v0.12.0}
        TORCHTEXT_VERSION_TAG: ${TORCHTEXT_VERSION_TAG:-v0.12.0}
        PROJECT_ROOT: ${PROJECT_ROOT:-/opt/project}
        GID: ${GID:-1000}
        UID: ${UID:-1000}
        GRP: ${GRP:-user}
        USR: ${USR:-user}
        TZ: ${TZ:-Asia/Seoul}
        # URL for faster `apt` and `pip` installs. Optimized for Korean users.
        # Use URLs optimized for user location and security requirements.
        DEB_OLD: ${DEB_OLD:-http://archive.ubuntu.com}
        DEB_NEW: ${DEB_NEW:-http://mirror.kakao.com}
        # Comment out the PyPI mirrors to use the default PyPI repository.
#        INDEX_URL: ${INDEX_URL:-http://mirror.kakao.com/pypi/simple}
#        TRUSTED_HOST: ${TRUSTED_HOST:-mirror.kakao.com}
    working_dir: ${PROJECT_ROOT:-/opt/project}
    user: ${UID:-1000}:${GID:-1000}
    environment:
      TZ: ${TZ:-Asia/Seoul}
      CUDA_DEVICE_ORDER: PCI_BUS_ID
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]


  deploy:
    hostname: deploy
    image: cresset:${IMAGE_NAME:-deploy}
    tty: true
    init: true
    stdin_open: true
    volumes:  # Place user-specific directories in `docker-compose.override.yaml`.
      - .:${PROJECT_ROOT:-/opt/project}
    build:
      target: deploy
      context: .
      dockerfile: Dockerfile
      args:
        BUILD_MODE: ${BUILD_MODE:-exclude}
        # The Anaconda `defaults` channel is not free for commercial use.
        BUILD_TEST: 1  # Enable build tests for deployment.
        BUILD_CAFFE2: 1  # Caffe2 should be enabled in production settings.
        BUILD_CAFFE2_OPS: 1
        USE_NNPACK: 1  # Enable NNPack for deployment.
        USE_QNNPACK: 1  # Enable QNNPack for deployment.
        LINUX_DISTRO: ${LINUX_DISTRO:-ubuntu}
        DISTRO_VERSION: ${DISTRO_VERSION:-20.04}
        CUDA_VERSION: ${CUDA_VERSION:-11.5.2}
        CUDNN_VERSION: ${CUDNN_VERSION:-8}
        PYTHON_VERSION: ${PYTHON_VERSION:-3.9}
        # Requirements must include `mkl` if `MKL_MODE` is set to `include` for deployment.
        MKL_MODE: ${MKL_MODE:-include}  # `include` or `exclude`. Disabled by default for deployment.
        TORCH_CUDA_ARCH_LIST: ${CCA}  # This will fail if BUILD_MODE=include but CCA is not set explicitly.
        PYTORCH_VERSION_TAG: ${PYTORCH_VERSION_TAG:-v1.11.0}
        TORCHVISION_VERSION_TAG: ${TORCHVISION_VERSION_TAG:-v0.12.0}
        TORCHTEXT_VERSION_TAG: ${TORCHTEXT_VERSION_TAG:-v0.12.0}
        PROJECT_ROOT: ${PROJECT_ROOT:-/opt/project}
        DEB_OLD: ${DEB_OLD:-http://archive.ubuntu.com}
        DEB_NEW: ${DEB_NEW:-http://mirror.kakao.com}
#        INDEX_URL: ${INDEX_URL:-http://mirror.kakao.com/pypi/simple}
#        TRUSTED_HOST: ${TRUSTED_HOST:-mirror.kakao.com}
    working_dir: ${PROJECT_ROOT:-/opt/project}
    environment:
      CUDA_DEVICE_ORDER: PCI_BUS_ID
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]


  # This layer may be useful for PyTorch contributors.
  devel:  # Skeleton service for development and debugging.
    hostname: devel
    image: cresset:${IMAGE_NAME:-devel}
    tty: true
    init: true
    stdin_open: true
    volumes:
      - .:${PROJECT_ROOT:-/opt/project}
    build:
      target: ${TARGET_STAGE:-build-base}  # All builds begin at `build-base`.
      context: .
      dockerfile: Dockerfile


  ngc:  # NGC image service. Demonstrates the generality of the template.
    hostname: ngc
    image: cresset:ngc-${YEAR:-22}.${MONTH:-02}
#    ipc: host
    tty: true
    init: true
    stdin_open: true
    volumes:
      - .:${PROJECT_ROOT:-/opt/project}
    build:
      target: ngc
      context: .
      dockerfile: misc/ngc.Dockerfile
      args:
        PROJECT_ROOT: ${PROJECT_ROOT:-/opt/project}
        YEAR: ${YEAR:-22}
        MONTH: ${MONTH:-02}
        GID: ${GID:-1000}
        UID: ${UID:-1000}
        GRP: ${GRP:-user}
        USR: ${USR:-user}
        TZ: ${TZ:-Asia/Seoul}
    working_dir: ${PROJECT_ROOT:-/opt/project}
    user: ${UID:-1000}:${GID:-1000}
    environment:
      TZ: ${TZ:-Asia/Seoul}
      CUDA_DEVICE_ORDER: PCI_BUS_ID
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
